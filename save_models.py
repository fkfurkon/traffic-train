"""
Save Models Script
‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
"""

import os
import sys
import joblib
import pickle
import pandas as pd
import numpy as np
from datetime import datetime

def save_trained_models(xgb_model, lstm_model, scaler, feature_columns, 
                       sarima_model=None, save_dir="./models/"):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    
    ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:
    1. ‡∏£‡∏±‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å‡∏à‡∏ô‡∏à‡∏ö
    2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
    """
    
    print("üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å XGBoost
        joblib.dump(xgb_model, f"{save_dir}xgb_model.pkl")
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å XGBoost model ‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å LSTM
        lstm_model.save(f"{save_dir}lstm_model.h5")
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å LSTM model ‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Scaler
        joblib.dump(scaler, f"{save_dir}scaler.pkl")
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Scaler ‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å feature columns
        with open(f"{save_dir}feature_columns.pkl", 'wb') as f:
            pickle.dump(feature_columns, f)
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Feature columns ‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å SARIMA (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        if sarima_model:
            joblib.dump(sarima_model, f"{save_dir}sarima_model.pkl")
            print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å SARIMA model ‡πÅ‡∏•‡πâ‡∏ß")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata
        metadata = {
            'saved_at': datetime.now().isoformat(),
            'models_saved': ['xgb', 'lstm', 'scaler'],
            'feature_count': len(feature_columns),
            'feature_columns': feature_columns
        }
        
        if sarima_model:
            metadata['models_saved'].append('sarima')
            
        with open(f"{save_dir}metadata.json", 'w') as f:
            import json
            json.dump(metadata, f, indent=2)
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metadata ‡πÅ‡∏•‡πâ‡∏ß")
        
        print(f"\nüéâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà {save_dir}")
        print(f"üìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å:")
        for file in os.listdir(save_dir):
            print(f"   - {file}")
            
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {str(e)}")

def create_model_save_cell():
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á code cell ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å
    """
    code = '''
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
from save_models import save_trained_models

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß)
save_trained_models(
    xgb_model=xgb_model,
    lstm_model=lstm_model,
    scaler=scaler,
    feature_columns=feature_cols,
    sarima_model=sarima_fitted if sarima_success else None
)

print("üéØ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!")
print("üîß ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:")
print("1. ‡∏£‡∏±‡∏ô: python traffic_api.py (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API)")
print("2. ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ model_deployment_guide.py ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á")
'''
    
    return code

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö
def test_saved_models(models_dir="./models/"):
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
    """
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ...")
    
    from model_deployment_guide import TrafficForecastingSystem
    from datetime import datetime
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏∞‡∏ö‡∏ö
    system = TrafficForecastingSystem()
    system.load_models(models_dir)
    
    if not system.is_trained:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")
        return False
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    test_time = datetime.now()
    test_vehicle_count = 45
    test_historical = [40, 42, 44, 43, 45, 47, 46, 45]
    
    try:
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö XGBoost
        features = system.prepare_features(test_time, test_vehicle_count, [43, 45, 47])
        xgb_pred = system.predict_xgboost(features)
        print(f"‚úÖ XGBoost prediction: {xgb_pred:.2f}")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö LSTM (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 24 ‡∏à‡∏∏‡∏î)
        if len(test_historical) >= 24:
            lstm_pred = system.predict_lstm(test_historical[-24:])
            print(f"‚úÖ LSTM prediction: {lstm_pred:.2f}")
        else:
            # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö 24 ‡∏à‡∏∏‡∏î
            extended_historical = test_historical + [test_vehicle_count] * (24 - len(test_historical))
            lstm_pred = system.predict_lstm(extended_historical)
            print(f"‚úÖ LSTM prediction (extended data): {lstm_pred:.2f}")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö ensemble
        result = system.predict_ensemble(
            timestamp=test_time,
            vehicle_count=test_vehicle_count,
            sequence_data=test_historical,
            lag_values=[43, 45, 47]
        )
        
        print(f"‚úÖ Ensemble prediction: {result['ensemble_prediction']:.2f}")
        print(f"   Individual models: {result['individual_predictions']}")
        
        print("\nüéâ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î!")
        return True
        
    except Exception as e:
        print(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e)}")
        return False

if __name__ == "__main__":
    print("üìù Model Save Script")
    print("=" * 50)
    
    print("\nüîß ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:")
    print("1. ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å‡∏à‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à")
    print("2. ‡πÄ‡∏û‡∏¥‡πà‡∏° code cell ‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å:")
    print("\n" + create_model_save_cell())
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if os.path.exists("./models/"):
        print("\nüîç ‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models/ ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
        print("üìã ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:")
        for file in os.listdir("./models/"):
            print(f"   - {file}")
            
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        test_choice = input("\n‚ùì ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? (y/n): ")
        if test_choice.lower() == 'y':
            test_saved_models()
    else:
        print("\n‚ö†Ô∏è  ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models/")
        print("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
        
    print("\nüìö ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:")
    print("1. ‡∏£‡∏±‡∏ô: python traffic_api.py (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API)")
    print("2. ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á:")
    print("""
from model_deployment_guide import create_prediction_pipeline
predict_func = create_prediction_pipeline()
result = predict_func(datetime.now(), 45, [40, 42, 44])
print(result)
    """)
